{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import scikit_posthocs as sp\n",
    "#import statistics as stats\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "#from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "#from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#!pip install sklearn_lvq\n",
    "from sklearn_lvq import GlvqModel\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from deslib.dcs import OLA\n",
    "from deslib.dcs import MCB\n",
    "from deslib.dcs import LCA\n",
    "from deslib.des import KNORAU\n",
    "from deslib.des.knora_e import KNORAE\n",
    "from deslib.des import METADES\n",
    "\n",
    "from datetime import datetime\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import friedmanchisquare\n",
    "from scipy.stats import kruskal\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code has been written for the following versions of the most relevant libraries:\n",
    "# Scikit-learn v0.23.1, sklearn_lvq v1.1.0, xgboost 1.2.1, DESlib v0.3.5 e SciPy v1.5.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let's build a function to convert KEEL data to a regular CSV (remove annotations before data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keel2csv(file):\n",
    "    ''' Reads a KEEL .dat file, converts it into a regular CSV data file \n",
    "    that contains a header line. The output .csv file is written to the same \n",
    "    dir as the original .dat file. This function also returns a dict \n",
    "    {'numeric':[], 'nominal':[]} containg two lists, one for the numeric \n",
    "    attributes and the other for the nominal atributes.'''\n",
    "    filename = file.name\n",
    "    # Let's read the attribute types (useful for preprocessing) and also the \n",
    "    # column names from the @annotations, inclunding the target (class) column:\n",
    "    has_inputs = has_outputs = False\n",
    "    numeric_atts = []\n",
    "    nominal_atts = []\n",
    "    for line in file:\n",
    "        if '@attribute' in line:\n",
    "            if (' real' in line) or (' integer' in line):\n",
    "                numeric_atts.append(line.split(' ')[1])\n",
    "            elif '{' in line:\n",
    "                nominal_atts.append(line.split(' ')[1])\n",
    "        if line.startswith('@inputs'):\n",
    "            att_names = line[8:-1].replace(' ', '')\n",
    "            has_inputs = True\n",
    "        elif line.startswith('@input'):\n",
    "            att_names = line[7:-1].replace(' ', '')\n",
    "            has_inputs = True\n",
    "        elif line.startswith('@outputs') or line.startswith('@output'):\n",
    "            class_name = line[9:-1]\n",
    "            has_outputs = True\n",
    "            break\n",
    "        elif line.startswith('@output'):\n",
    "            class_name = line[8:-1]\n",
    "            has_outputs = True\n",
    "            break\n",
    "    if (not has_inputs) or (not has_outputs):\n",
    "        print('File ', filename, 'missing annotations?' )\n",
    "\n",
    "    columns = att_names + ',' + class_name\n",
    "\n",
    "    #Then, lets remove the annotations and save the column names and data into a csv file:\n",
    "    lines = file.readlines() \n",
    "    file.close()\n",
    "    new_file = open(filename[:-4]+'.csv','w')\n",
    "    new_file.write(columns+'\\n')\n",
    "    for line in lines:\n",
    "        if not line.startswith('@'):\n",
    "            new_file.write(line)\n",
    "    new_file.close()    \n",
    "    return {'numeric':numeric_atts, 'nominal':nominal_atts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we need to run through the files and execute the keel2csv function for each KEEL dat file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = './KEEL_imb_classification_data_5-fold'\n",
    "dl_file = open(rootdir+'/dir_list.txt', 'r')\n",
    "ds_names = dl_file.readline().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting KEEL .dat files to CSV:\n",
    "att_types = {} #This dictionary will have each dataset name as key and will hold the attribute types.\n",
    "for name in ds_names:\n",
    "    for fold in range(1,6):\n",
    "        full_path = rootdir+'/'+name+'/'+name[:-4]+str(fold)+'tra.dat' \n",
    "        f = open(full_path, 'r')\n",
    "        att_types[name] = keel2csv(f)\n",
    "        f.close()\n",
    "        full_path = rootdir+'/'+name+'/'+name[:-4]+str(fold)+'tst.dat' \n",
    "        f = open(full_path, 'r')\n",
    "        keel2csv(f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing datasets with no numeric attributes:\n",
    "to_remove = []\n",
    "for name in ds_names:\n",
    "    if len(att_types[name]['numeric']) == 0:\n",
    "        to_remove.append(name)\n",
    "\n",
    "for name in to_remove:\n",
    "    ds_names.remove(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ok, now that we finally have all the data in CSV format, lets load them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3437: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# I will create a dict structure such that I can access train fold 1 from \n",
    "# dataset wisconsin as datasets['wisconsin']['train'][0]\n",
    "\n",
    "datasets = {}\n",
    "for name in ds_names:\n",
    "    datasets[name] = {}\n",
    "    datasets[name]['train'] = []\n",
    "    datasets[name]['test'] = []\n",
    "    for fold in range(1,6):\n",
    "        csv_filename = rootdir+'/'+name+'/'+name[:-4]+str(fold)+'tra.csv'\n",
    "        df_train = pd.read_csv(csv_filename, encoding='utf8', engine='python', sep=',', \n",
    "                     header=0, error_bad_lines=False)\n",
    "        csv_filename = rootdir+'/'+name+'/'+name[:-4]+str(fold)+'tst.csv'\n",
    "        df_test = pd.read_csv(csv_filename, encoding='utf8', engine='python', sep=',', \n",
    "                     header=0, error_bad_lines=False)\n",
    "        datasets[name]['train'].append(df_train)\n",
    "        datasets[name]['test'].append(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The att_types dictionary will allow us to do things like selecting only the numeric attributes from a dataset very easily, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's take a look at the second dataset, for example:\n",
    "# print(ds_names[1])\n",
    "# datasets[ds_names[1]]['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now a subset of it containing only the attributes stated as integer or real:\n",
    "# datasets[ds_names[1]]['train'][0][att_types[ds_names[1]]['numeric']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Imbalance Ratios (IRs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count how many instances we have per class and calculate the imbalance ratios:\n",
    "cnts = {}\n",
    "imb_ratios = {}\n",
    "for key in datasets:\n",
    "    #First let's create a dataframe containing all data (appending train and test):\n",
    "    ds = datasets[key]['train'][0].append(datasets[key]['test'][0], ignore_index=True)\n",
    "    class_att = ds.columns[-1]\n",
    "    cnt = Counter(ds[class_att])\n",
    "    cnts[key] = (cnt[list(cnt)[0]], cnt[list(cnt)[1]])\n",
    "    imb_ratios[key] = max(cnts[key])/min(cnts[key])\n",
    "#for i in imb_ratios.values(): print('%.2f'%i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting Datasets by IR to help future analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sort the datasets names in ds_names by their corresponding IR in imb_ratios dict.\n",
    "d = imb_ratios\n",
    "#d = { for sorted(imb_ratios.values())\n",
    "def getkeybyvalue(d,i):\n",
    "    for k, v in d.items():\n",
    "        if v == i:\n",
    "            return (k)\n",
    "\n",
    "sortvaluelist = sorted(d.values())\n",
    "sortresult ={}\n",
    "for i1 in sortvaluelist:   \n",
    "    key = getkeybyvalue(d,i1)\n",
    "    sortresult[key] = i1\n",
    "\n",
    "ds_names = list(sortresult.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing dataset lymphography-normal-fibrosis-5-fold\n",
      "Removing dataset kddcup-guess_passwd_vs_satan-5-fold\n",
      "Removing dataset kddcup-land_vs_portsweep-5-fold\n",
      "Removing dataset kddcup-buffer_overflow_vs_back-5-fold\n",
      "Removing dataset kddcup-rootkit-imap_vs_back-5-fold\n"
     ]
    }
   ],
   "source": [
    "# Removing datasets with too many categorical features:\n",
    "for name in ds_names:\n",
    "     if len(att_types[name]['nominal'][:-1]) >= 5:\n",
    "            print('Removing dataset', name)\n",
    "            ds_names.remove(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing dataset kddcup-land_vs_satan-5-fold\n"
     ]
    }
   ],
   "source": [
    "# Removing datasets with too many categorical features:\n",
    "for name in ds_names:\n",
    "     if len(att_types[name]['nominal'][:-1]) >= 5:\n",
    "            print('Removing dataset', name)\n",
    "            ds_names.remove(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abalone-17_vs_7-8-9-10-5-fold': 39.310344827586206,\n",
       " 'abalone-19_vs_10-11-12-13-5-fold': 49.6875,\n",
       " 'abalone-20_vs_8-9-10-5-fold': 72.6923076923077,\n",
       " 'abalone-21_vs_8-5-fold': 40.5,\n",
       " 'abalone-3_vs_11-5-fold': 32.46666666666667,\n",
       " 'abalone19-5-fold': 129.4375,\n",
       " 'abalone9-18-5-fold': 16.404761904761905,\n",
       " 'cleveland-0_vs_4-5-fold': 12.307692307692308,\n",
       " 'dermatology-6-5-fold': 16.9,\n",
       " 'ecoli-0-1-3-7_vs_2-6-5-fold': 39.142857142857146,\n",
       " 'ecoli-0-1-4-6_vs_5-5-fold': 13.0,\n",
       " 'ecoli-0-1-4-7_vs_2-3-5-6-5-fold': 10.586206896551724,\n",
       " 'ecoli-0-1-4-7_vs_5-6-5-fold': 12.28,\n",
       " 'ecoli-0-1_vs_2-3-5-5-fold': 9.166666666666666,\n",
       " 'ecoli-0-1_vs_5-5-fold': 11.0,\n",
       " 'ecoli-0-2-3-4_vs_5-5-fold': 9.1,\n",
       " 'ecoli-0-2-6-7_vs_3-5-5-fold': 9.181818181818182,\n",
       " 'ecoli-0-3-4-6_vs_5-5-fold': 9.25,\n",
       " 'ecoli-0-3-4-7_vs_5-6-5-fold': 9.28,\n",
       " 'ecoli-0-3-4_vs_5-5-fold': 9.0,\n",
       " 'ecoli-0-4-6_vs_5-5-fold': 9.15,\n",
       " 'ecoli-0-6-7_vs_3-5-5-fold': 9.090909090909092,\n",
       " 'ecoli-0-6-7_vs_5-5-fold': 10.0,\n",
       " 'ecoli-0_vs_1-5-fold': 1.8571428571428572,\n",
       " 'ecoli1-5-fold': 3.3636363636363638,\n",
       " 'ecoli2-5-fold': 5.461538461538462,\n",
       " 'ecoli3-5-fold': 8.6,\n",
       " 'ecoli4-5-fold': 15.8,\n",
       " 'glass-0-1-2-3_vs_4-5-6-5-fold': 3.196078431372549,\n",
       " 'glass-0-1-4-6_vs_2-5-fold': 11.058823529411764,\n",
       " 'glass-0-1-5_vs_2-5-fold': 9.117647058823529,\n",
       " 'glass-0-1-6_vs_2-5-fold': 10.294117647058824,\n",
       " 'glass-0-1-6_vs_5-5-fold': 19.444444444444443,\n",
       " 'glass-0-4_vs_5-5-fold': 9.222222222222221,\n",
       " 'glass-0-6_vs_5-5-fold': 11.0,\n",
       " 'glass0-5-fold': 2.057142857142857,\n",
       " 'glass1-5-fold': 1.8157894736842106,\n",
       " 'glass2-5-fold': 11.588235294117647,\n",
       " 'glass4-5-fold': 15.461538461538462,\n",
       " 'glass5-5-fold': 22.77777777777778,\n",
       " 'glass6-5-fold': 6.379310344827586,\n",
       " 'haberman-5-fold': 2.7777777777777777,\n",
       " 'iris0-5-fold': 2.0,\n",
       " 'kddcup-buffer_overflow_vs_back-5-fold': 73.43333333333334,\n",
       " 'kddcup-guess_passwd_vs_satan-5-fold': 29.9811320754717,\n",
       " 'kddcup-land_vs_portsweep-5-fold': 49.523809523809526,\n",
       " 'kddcup-land_vs_satan-5-fold': 75.66666666666667,\n",
       " 'kddcup-rootkit-imap_vs_back-5-fold': 100.13636363636364,\n",
       " 'led7digit-0-2-4-5-6-7-8-9_vs_1-5-fold': 10.972972972972974,\n",
       " 'lymphography-normal-fibrosis-5-fold': 23.666666666666668,\n",
       " 'new-thyroid1-5-fold': 5.142857142857143,\n",
       " 'new-thyroid2-5-fold': 5.142857142857143,\n",
       " 'page-blocks-1-3_vs_4-5-fold': 15.857142857142858,\n",
       " 'page-blocks0-5-fold': 8.788908765652952,\n",
       " 'pima-5-fold': 1.8656716417910448,\n",
       " 'poker-8-9_vs_5-5-fold': 82.0,\n",
       " 'poker-8-9_vs_6-5-fold': 58.4,\n",
       " 'poker-8_vs_6-5-fold': 85.88235294117646,\n",
       " 'poker-9_vs_7-5-fold': 29.5,\n",
       " 'segment0-5-fold': 6.015197568389058,\n",
       " 'shuttle-2_vs_5-5-fold': 66.6734693877551,\n",
       " 'shuttle-6_vs_2-3-5-fold': 22.0,\n",
       " 'shuttle-c0-vs-c4-5-fold': 13.869918699186991,\n",
       " 'shuttle-c2-vs-c4-5-fold': 20.5,\n",
       " 'vehicle0-5-fold': 3.251256281407035,\n",
       " 'vehicle1-5-fold': 2.8986175115207375,\n",
       " 'vehicle2-5-fold': 2.8807339449541285,\n",
       " 'vehicle3-5-fold': 2.990566037735849,\n",
       " 'vowel0-5-fold': 9.977777777777778,\n",
       " 'winequality-red-3_vs_5-5-fold': 68.1,\n",
       " 'winequality-red-4-5-fold': 29.169811320754718,\n",
       " 'winequality-red-8_vs_6-5-fold': 35.44444444444444,\n",
       " 'winequality-red-8_vs_6-7-5-fold': 46.5,\n",
       " 'winequality-white-3-9_vs_5-5-fold': 58.28,\n",
       " 'winequality-white-3_vs_7-5-fold': 44.0,\n",
       " 'winequality-white-9_vs_4-5-fold': 32.6,\n",
       " 'wisconsin-5-fold': 1.8577405857740585,\n",
       " 'yeast-0-2-5-6_vs_3-7-8-9-5-fold': 9.141414141414142,\n",
       " 'yeast-0-2-5-7-9_vs_3-6-8-5-fold': 9.141414141414142,\n",
       " 'yeast-0-3-5-9_vs_7-8-5-fold': 9.12,\n",
       " 'yeast-0-5-6-7-9_vs_4-5-fold': 9.352941176470589,\n",
       " 'yeast-1-2-8-9_vs_7-5-fold': 30.566666666666666,\n",
       " 'yeast-1-4-5-8_vs_7-5-fold': 22.1,\n",
       " 'yeast-1_vs_7-5-fold': 14.3,\n",
       " 'yeast-2_vs_4-5-fold': 9.07843137254902,\n",
       " 'yeast-2_vs_8-5-fold': 23.1,\n",
       " 'yeast1-5-fold': 2.4592074592074593,\n",
       " 'yeast3-5-fold': 8.104294478527608,\n",
       " 'yeast4-5-fold': 28.098039215686274,\n",
       " 'yeast5-5-fold': 32.72727272727273,\n",
       " 'yeast6-5-fold': 41.4}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imb_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying dataset info as a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|#|Dataset name|Numeric atts|Nominal atts|Class counts|IR|\n",
       "|-|:-----------|:----------:|:----------:|:----------:|--|\n",
       "|1|glass1                             |9|0|(138, 76)|1.82|\n",
       "|2|ecoli-0_vs_1                       |7|0|(143, 77)|1.86|\n",
       "|3|wisconsin                          |9|0|(444, 239)|1.86|\n",
       "|4|pima                               |8|0|(268, 500)|1.87|\n",
       "|5|iris0                              |4|0|(50, 100)|2.00|\n",
       "|6|glass0                             |9|0|(70, 144)|2.06|\n",
       "|7|yeast1                             |8|0|(1055, 429)|2.46|\n",
       "|8|haberman                           |3|0|(225, 81)|2.78|\n",
       "|9|vehicle2                           |18|0|(628, 218)|2.88|\n",
       "|10|vehicle1                           |18|0|(629, 217)|2.90|\n",
       "|11|vehicle3                           |18|0|(634, 212)|2.99|\n",
       "|12|glass-0-1-2-3_vs_4-5-6             |9|0|(163, 51)|3.20|\n",
       "|13|vehicle0                           |18|0|(199, 647)|3.25|\n",
       "|14|ecoli1                             |7|0|(259, 77)|3.36|\n",
       "|15|new-thyroid1                       |5|0|(180, 35)|5.14|\n",
       "|16|ecoli2                             |7|0|(284, 52)|5.46|\n",
       "|17|segment0                           |19|0|(1979, 329)|6.02|\n",
       "|18|glass6                             |9|0|(185, 29)|6.38|\n",
       "|19|yeast3                             |8|0|(1321, 163)|8.10|\n",
       "|20|ecoli3                             |7|0|(301, 35)|8.60|\n",
       "|21|page-blocks0                       |10|0|(4913, 559)|8.79|\n",
       "|22|ecoli-0-3-4_vs_5                   |7|0|(180, 20)|9.00|\n",
       "|23|yeast-2_vs_4                       |8|0|(463, 51)|9.08|\n",
       "|24|ecoli-0-6-7_vs_3-5                 |7|0|(200, 22)|9.09|\n",
       "|25|ecoli-0-2-3-4_vs_5                 |7|0|(182, 20)|9.10|\n",
       "|26|glass-0-1-5_vs_2                   |9|0|(155, 17)|9.12|\n",
       "|27|yeast-0-3-5-9_vs_7-8               |8|0|(456, 50)|9.12|\n",
       "|28|yeast-0-2-5-6_vs_3-7-8-9           |8|0|(905, 99)|9.14|\n",
       "|29|ecoli-0-4-6_vs_5                   |6|0|(183, 20)|9.15|\n",
       "|30|ecoli-0-1_vs_2-3-5                 |7|0|(220, 24)|9.17|\n",
       "|31|ecoli-0-2-6-7_vs_3-5               |7|0|(202, 22)|9.18|\n",
       "|32|glass-0-4_vs_5                     |9|0|(83, 9)|9.22|\n",
       "|33|ecoli-0-3-4-6_vs_5                 |7|0|(185, 20)|9.25|\n",
       "|34|ecoli-0-3-4-7_vs_5-6               |7|0|(232, 25)|9.28|\n",
       "|35|yeast-0-5-6-7-9_vs_4               |8|0|(477, 51)|9.35|\n",
       "|36|vowel0                             |13|0|(90, 898)|9.98|\n",
       "|37|ecoli-0-6-7_vs_5                   |6|0|(200, 20)|10.00|\n",
       "|38|glass-0-1-6_vs_2                   |9|0|(175, 17)|10.29|\n",
       "|39|ecoli-0-1-4-7_vs_2-3-5-6           |7|0|(307, 29)|10.59|\n",
       "|40|led7digit-0-2-4-5-6-7-8-9_vs_1     |7|0|(406, 37)|10.97|\n",
       "|41|ecoli-0-1_vs_5                     |6|0|(220, 20)|11.00|\n",
       "|42|glass-0-1-4-6_vs_2                 |9|0|(188, 17)|11.06|\n",
       "|43|glass2                             |9|0|(197, 17)|11.59|\n",
       "|44|ecoli-0-1-4-7_vs_5-6               |6|0|(307, 25)|12.28|\n",
       "|45|cleveland-0_vs_4                   |13|0|(160, 13)|12.31|\n",
       "|46|ecoli-0-1-4-6_vs_5                 |6|0|(260, 20)|13.00|\n",
       "|47|shuttle-c0-vs-c4                   |9|0|(1706, 123)|13.87|\n",
       "|48|yeast-1_vs_7                       |7|0|(429, 30)|14.30|\n",
       "|49|glass4                             |9|0|(201, 13)|15.46|\n",
       "|50|ecoli4                             |7|0|(316, 20)|15.80|\n",
       "|51|page-blocks-1-3_vs_4               |10|0|(444, 28)|15.86|\n",
       "|52|abalone9-18                        |7|1|(689, 42)|16.40|\n",
       "|53|dermatology-6                      |34|0|(338, 20)|16.90|\n",
       "|54|glass-0-1-6_vs_5                   |9|0|(175, 9)|19.44|\n",
       "|55|shuttle-c2-vs-c4                   |9|0|(6, 123)|20.50|\n",
       "|56|shuttle-6_vs_2-3                   |9|0|(220, 10)|22.00|\n",
       "|57|yeast-1-4-5-8_vs_7                 |8|0|(663, 30)|22.10|\n",
       "|58|glass5                             |9|0|(205, 9)|22.78|\n",
       "|59|yeast-2_vs_8                       |8|0|(462, 20)|23.10|\n",
       "|60|yeast4                             |8|0|(1433, 51)|28.10|\n",
       "|61|winequality-red-4                  |11|0|(1546, 53)|29.17|\n",
       "|62|poker-9_vs_7                       |10|0|(236, 8)|29.50|\n",
       "|63|yeast-1-2-8-9_vs_7                 |8|0|(917, 30)|30.57|\n",
       "|64|abalone-3_vs_11                    |7|1|(15, 487)|32.47|\n",
       "|65|winequality-white-9_vs_4           |11|0|(163, 5)|32.60|\n",
       "|66|yeast5                             |8|0|(1440, 44)|32.73|\n",
       "|67|winequality-red-8_vs_6             |11|0|(638, 18)|35.44|\n",
       "|68|ecoli-0-1-3-7_vs_2-6               |7|0|(274, 7)|39.14|\n",
       "|69|abalone-17_vs_7-8-9-10             |7|1|(2280, 58)|39.31|\n",
       "|70|abalone-21_vs_8                    |7|1|(14, 567)|40.50|\n",
       "|71|yeast6                             |8|0|(1449, 35)|41.40|\n",
       "|72|winequality-white-3_vs_7           |11|0|(880, 20)|44.00|\n",
       "|73|winequality-red-8_vs_6-7           |11|0|(837, 18)|46.50|\n",
       "|74|abalone-19_vs_10-11-12-13          |7|1|(32, 1590)|49.69|\n",
       "|75|winequality-white-3-9_vs_5         |11|0|(1457, 25)|58.28|\n",
       "|76|poker-8-9_vs_6                     |10|0|(1460, 25)|58.40|\n",
       "|77|shuttle-2_vs_5                     |9|0|(3267, 49)|66.67|\n",
       "|78|winequality-red-3_vs_5             |11|0|(681, 10)|68.10|\n",
       "|79|abalone-20_vs_8-9-10               |7|1|(1890, 26)|72.69|\n",
       "|80|poker-8-9_vs_5                     |10|0|(2050, 25)|82.00|\n",
       "|81|poker-8_vs_6                       |10|0|(1460, 17)|85.88|\n",
       "|82|abalone19                          |7|1|(4142, 32)|129.44|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print('Dataset name'.ljust(35),'\\tClass counts\\tIR')\n",
    "#for k in ds_names: print(str(k).ljust(35),'\\t',cnts[k],'\\t', imb_ratios[k])\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "#open('table.txt', 'w').close()\n",
    "tab_file = open('table.txt', 'w')\n",
    "tab_file\n",
    "tab_file.write('|#|Dataset name|Numeric atts|Nominal atts|Class counts|IR|\\n')\n",
    "tab_file.write('|-|:-----------|:----------:|:----------:|:----------:|--|\\n')\n",
    "n = 1\n",
    "for k in ds_names:\n",
    "    num_att = len(att_types[k]['numeric'])\n",
    "    nom_att = len(att_types[k]['nominal'][:-1])\n",
    "    tab_file.write('|'+str(n)+'|'+str(k)[:-7].ljust(35)+'|'+str(num_att)+'|'+str(nom_att)+'|'+str(cnts[k])+'|'+('%.2f'%imb_ratios[k])+'|\\n')\n",
    "    n+=1\n",
    "tab_file.close()\n",
    "display(Markdown(filename='./table.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning (stripping) strings within dataframe and also changing class labels to 1 and 0.\n",
    "for name in ds_names:\n",
    "    for s in ['train', 'test']:\n",
    "        for fold in range(5):\n",
    "            df = datasets[name][s][fold]\n",
    "            df_obj = df.select_dtypes(['object'])\n",
    "            df[df_obj.columns] = df_obj.apply(lambda x: x.str.strip())\n",
    "            class_att = df.columns[-1]\n",
    "            #print(class_att)\n",
    "            #df[class_att] = df[class_att].replace(['positive', 'negative'],[1,0])\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing values\n",
    "\n",
    "Applying a Simple Imputer to the numeric attributes when there are missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "for name in ds_names:\n",
    "    ds = datasets[name]['train'][0].append(datasets[name]['test'][0], ignore_index=True) #full dataset.\n",
    "    if df.isnull().values.any(): \n",
    "        print('There is(are) missing values on ', name)\n",
    "        imp_mean.fit(ds[att_types[name]['numeric']]) #Fit on full dataset.\n",
    "        for s in ['train', 'test']:\n",
    "            for fold in range(5):\n",
    "                datasets[name][s][fold][att_types[name]['numeric']] = imp_mean.transform(datasets[name][s][fold][att_types[name]['numeric']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were no missing values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "\n",
    "Here we must apply this encoding method to the nominal attributes in order to allow them to be managed by the classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's join the dataset (train+test), find all unique values for nominal columns, and store them\n",
    "# in a dict. \n",
    "unique_values = {n:None for n in ds_names}\n",
    "for name in ds_names:\n",
    "    unique_values[name] = {k:None for k in att_types[name]['nominal'][:-1]}\n",
    "    ds = datasets[name]['train'][0].append(datasets[name]['test'][0], ignore_index=True)\n",
    "    for att in att_types[name]['nominal'][:-1]:#For each nominal attribute, except the target one (last one)\n",
    "        unique_values[name][att] = ds[att].unique()\n",
    "        \n",
    "# Before applying the encoding, we will cast each nominal attribute to CategoricalDtype in order to explicitly \n",
    "# set all their possible values. This will avoid different encodings (thus, different dimensions) in train/test sets.\n",
    "for name in ds_names:    \n",
    "    for s in ['train', 'test']:\n",
    "        for fold in range(5):\n",
    "            for att in att_types[name]['nominal'][:-1]: #For each nominal attribute, except the target one (last one)\n",
    "                datasets[name][s][fold][att] = datasets[name][s][fold][att].astype(CategoricalDtype(unique_values[name][att]))\n",
    "                att_encoded = pd.get_dummies(datasets[name][s][fold][att], prefix = att)\n",
    "                datasets[name][s][fold] = datasets[name][s][fold].drop([att], axis = 1)\n",
    "                datasets[name][s][fold] = pd.concat([att_encoded, datasets[name][s][fold]], axis = 1)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Let's take a look at the second dataset, for example:\n",
    "# print(ds_names[1])\n",
    "# datasets[ds_names[1]]['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "Here, the idea is to create 5 copies of each dataset, for each copy we are going to apply one of the following scaling techniques to the numeric attributes: Standard Scaler, Min-max Scaler, Maximum Absolute Scaler, Robust Scaler and Power Transformer.\n",
    "\n",
    "UPDATE 1: There is [a bug](https://github.com/scikit-learn/scikit-learn/issues/14959) in PowerTransformer that makes it fail for some of our datasets, I'll skip it for now. \n",
    "\n",
    "UPDATE 2: Instead of PowerTransformer, we will include QuantileTransformer which also outputs a distribution with a gaussian-like shape:\n",
    "\"This method transforms the features to follow a uniform or a normal distribution.  Therefore, for a given feature, this transformation tends to spread out the most frequent values. It also reduces the impact of (marginal) outliers: this is therefore a robust preprocessing scheme.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "mms = MinMaxScaler() \n",
    "mas = MaxAbsScaler() \n",
    "rs = RobustScaler()\n",
    "#pt = PowerTransformer()\n",
    "qt = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "datasets_ss = copy.deepcopy(datasets)\n",
    "datasets_mms = copy.deepcopy(datasets)\n",
    "datasets_mas = copy.deepcopy(datasets)\n",
    "datasets_rs = copy.deepcopy(datasets)\n",
    "#datasets_pt = copy.deepcopy(datasets)\n",
    "datasets_qt = copy.deepcopy(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Ignoring warnings from QuantileTransformer when number of samples is lower then 1000:\n",
    "warnings.filterwarnings(action = \"ignore\", category=UserWarning) \n",
    "\n",
    "for name in ds_names:\n",
    "    for fold in range(5):\n",
    "        #print(f'Dataset: {name}, fold {fold}.', end = '')\n",
    "        datasets_ss[name]['train'][fold][att_types[name]['numeric']] = ss.fit_transform(datasets_ss[name]['train'][fold][att_types[name]['numeric']])\n",
    "        datasets_ss[name]['test'][fold][att_types[name]['numeric']] = ss.transform(datasets_ss[name]['test'][fold][att_types[name]['numeric']])\n",
    "        datasets_mms[name]['train'][fold][att_types[name]['numeric']] = mms.fit_transform(datasets_mms[name]['train'][fold][att_types[name]['numeric']])\n",
    "        datasets_mms[name]['test'][fold][att_types[name]['numeric']] = mms.transform(datasets_mms[name]['test'][fold][att_types[name]['numeric']])\n",
    "        datasets_mas[name]['train'][fold][att_types[name]['numeric']] = mas.fit_transform(datasets_mas[name]['train'][fold][att_types[name]['numeric']])\n",
    "        datasets_mas[name]['test'][fold][att_types[name]['numeric']] = mas.transform(datasets_mas[name]['test'][fold][att_types[name]['numeric']])\n",
    "        datasets_rs[name]['train'][fold][att_types[name]['numeric']] = rs.fit_transform(datasets_rs[name]['train'][fold][att_types[name]['numeric']])\n",
    "        datasets_rs[name]['test'][fold][att_types[name]['numeric']] = rs.transform(datasets_rs[name]['test'][fold][att_types[name]['numeric']])\n",
    "        datasets_qt[name]['train'][fold][att_types[name]['numeric']] = qt.fit_transform(datasets_qt[name]['train'][fold][att_types[name]['numeric']])\n",
    "        datasets_qt[name]['test'][fold][att_types[name]['numeric']] = qt.transform(datasets_qt[name]['test'][fold][att_types[name]['numeric']])\n",
    "\n",
    "# Restablishing warnings:\n",
    "warnings.filterwarnings(action = \"default\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the effect of the different scaling methods in a certain variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a_name = 'ecoli2-5-fold'\n",
    "a_name = 'winequality-white-9_vs_4-5-fold'\n",
    "#a_name ='glass1-5-fold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograma(var: np.ndarray, title: str):\n",
    "    hist, bin_edges = np.histogram(var)\n",
    "    plt.figure()\n",
    "    plt.bar(bin_edges[:-1], hist, width=5)\n",
    "    #plt.xlim(min(bin_edges)-5, max(bin_edges)+5)\n",
    "    if min(bin_edges) > -8 and max(bin_edges) < +8: #if histogram is in the interval (-8, 8)\n",
    "        plt.xlim(-8, +8)\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.xlabel('Value',fontsize=15)\n",
    "    plt.ylabel('Frequency',fontsize=15)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(title,fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "v = att_types[a_name]['numeric'][4]\n",
    "print('Dataset:', a_name, 'attribute', v)\n",
    "    \n",
    "v1 = datasets[a_name]['train'][0][v]\n",
    "histograma(v1, 'Original (no scaling)')\n",
    "v2 = datasets_ss[a_name]['train'][0][v]\n",
    "histograma(v2, 'Standard Scaler')\n",
    "v3 = datasets_mms[a_name]['train'][0][v]\n",
    "histograma(v3, 'Min-Max Scaler')\n",
    "v4 = datasets_mas[a_name]['train'][0][v]\n",
    "histograma(v4, 'Max Abs Scaler')\n",
    "v5 = datasets_rs[a_name]['train'][0][v]\n",
    "histograma(v5, 'Robust Scaler')\n",
    "#v6 = datasets_pt[a_name]['train'][0][v]\n",
    "#histograma(v6, 'Power Transformer')\n",
    "v7 = datasets_qt[a_name]['train'][0][v]\n",
    "histograma(v7, 'Quantile Transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = [(v1, 'Original (no scaling)'), (v2, 'Standard Scaler'), (v3, 'Min-Max Scaler'),\n",
    "          (v4, 'Max Abs Scaler'), (v5, 'Robust Scaler'), #(v6, 'Power Transformer'), \n",
    "          (v7, 'Quantile Transformer')\n",
    "         ]\n",
    "print('*** Distribution is not normal if p-value < 0.05 ***')\n",
    "teste = []\n",
    "for v, st in tuples:\n",
    "    teste.append(v)\n",
    "    print(st+': Statistic = %.2f, p-value = %.4f'%stats.normaltest(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating functions to cross-validate models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, model_name, results_df):\n",
    "    superset = {'No scaling': datasets, 'Standard Scaler': datasets_ss,\n",
    "            'Min-Max Scaler': datasets_mms,'Max Abs Scaler':datasets_mas,\n",
    "            'Robust Scaler':datasets_rs, #'Power Transformer': datasets_pt, \n",
    "            'Quantile Transformer': datasets_qt}\n",
    "    \n",
    "    print('Starting '+ model_name +', time: ', datetime.now())\n",
    "    for name in ds_names:\n",
    "    #for name in ds_names[:5]:\n",
    "    #for name in [ds_names[10]]: #Testing with just one dataset\n",
    "        print('\\nCurrent dataset: '+name, end = '')\n",
    "        for k in superset:\n",
    "            print(' '+k+' ', end = '')\n",
    "            acc_folds = []\n",
    "            recall_folds = []\n",
    "            precision_folds = []\n",
    "            f1_folds = []\n",
    "            #roc_auc_folds = []\n",
    "            gmean_folds = []\n",
    "            \n",
    "            ds = superset[k]\n",
    "            target_att = ds[name]['train'][0].columns.tolist()[-1]\n",
    "            for fold in range(5):\n",
    "                print('.', end = '')\n",
    "                #Gather training data:\n",
    "                ds_train = ds[name]['train'][fold]\n",
    "                X_train = ds_train.drop(labels=target_att, axis = 1)\n",
    "                y_train = ds_train[target_att]\n",
    "            \n",
    "                # Gather test data:\n",
    "                ds_test = ds[name]['test'][fold]\n",
    "                X_test = ds_test.drop(labels=target_att, axis = 1)\n",
    "                y_test = ds_test[target_att]\n",
    "                \n",
    "                # Train model with the training data, \n",
    "                # If we need y_score for calculating ROC-AUC we do:\n",
    "                #y_score = model.fit(X_train, y_train).decision_function(X_test)\n",
    "                \n",
    "                # If we won't calculate ROC-AUC, we can just fit the model.\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # Test model:\n",
    "                y_pred = model.predict(X_test)\n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                recall = recall_score(y_test, y_pred, pos_label='positive')\n",
    "                precision = precision_score(y_test, y_pred, pos_label='positive', zero_division=0)\n",
    "                f1 = f1_score(y_test, y_pred, pos_label='positive', zero_division=0)\n",
    "                gmean = geometric_mean_score(y_test, y_pred, pos_label='positive')\n",
    "                #roc_auc = roc_auc_score(y_test, y_score)\n",
    "\n",
    "                # Store metrics for this fold\n",
    "                acc_folds.append(acc)\n",
    "                recall_folds.append(recall)\n",
    "                precision_folds.append(precision)\n",
    "                f1_folds.append(f1)\n",
    "                #roc_auc_folds.append(roc_auc)\n",
    "                gmean_folds.append(gmean)\n",
    "            \n",
    "            new_row = {'Dataset' : name, 'Scaling technique' : k, 'Model' : model_name,\n",
    "                       'acc_fold1' : acc_folds[0], 'acc_fold2' : acc_folds[1], 'acc_fold3' : acc_folds[2], \n",
    "                       'acc_fold4' : acc_folds[3], 'acc_fold5' : acc_folds[4], \n",
    "                       'acc_mean': np.mean(acc_folds), 'acc_stddev': np.std(acc_folds),\n",
    "                       'recall_fold1' : recall_folds[0], 'recall_fold2' : recall_folds[1], 'recall_fold3' : recall_folds[2],\n",
    "                       'recall_fold4' : recall_folds[3], 'recall_fold5' : recall_folds[4], \n",
    "                       'recall_mean': np.mean(recall_folds), 'recall_stddev':np.std(recall_folds),\n",
    "                       'precision_fold1' : precision_folds[0], 'precision_fold2' : precision_folds[1] , 'precision_fold3' : precision_folds[2],\n",
    "                       'precision_fold4' : precision_folds[3], 'precision_fold5' : precision_folds[4],\n",
    "                       'precision_mean': np.mean(precision_folds), 'precision_stddev': np.std(precision_folds),\n",
    "                       'f1_fold1' : f1_folds[0], 'f1_fold2' : f1_folds[1], 'f1_fold3' : f1_folds[2], \n",
    "                       'f1_fold4' : f1_folds[3], 'f1_fold5' : f1_folds[4], \n",
    "                       'f1_mean': np.mean(f1_folds), 'f1_stddev': np.std(f1_folds),\n",
    "                       'gmean_fold1' : gmean_folds[0], 'gmean_fold2' : gmean_folds[1], 'gmean_fold3' : gmean_folds[2], \n",
    "                       'gmean_fold4' : gmean_folds[3], 'gmean_fold5' : gmean_folds[4], \n",
    "                       'gmean_mean': np.mean(gmean_folds), 'gmean_stddev' : np.std(gmean_folds)\n",
    "                      }\n",
    "\n",
    "            results_df = results_df.append(new_row, ignore_index=True)\n",
    "\n",
    "    print('\\nFinishing '+ model_name +', time: ', datetime.now(),'\\n')   \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version is for ensemble models that need a prefit pool of base classifiers:\n",
    "def run_model2(model, model_name, pool, results_df):\n",
    "    superset = {'No scaling': datasets, 'Standard Scaler': datasets_ss,\n",
    "            'Min-Max Scaler': datasets_mms,'Max Abs Scaler':datasets_mas,\n",
    "            'Robust Scaler':datasets_rs, #'Power Transformer': datasets_pt, \n",
    "            'Quantile Transformer': datasets_qt}\n",
    "\n",
    "    print('Starting '+ model_name +', time: ', datetime.now())\n",
    "    for name in ds_names:\n",
    "    #for name in ds_names[:5]:\n",
    "        print('\\nCurrent dataset: '+name, end = '')\n",
    "        for k in superset:\n",
    "            print(' '+k+' ', end = '')\n",
    "            acc_folds = []\n",
    "            recall_folds = []\n",
    "            precision_folds = []\n",
    "            f1_folds = []\n",
    "            #roc_auc_folds = []\n",
    "            gmean_folds = []\n",
    "            \n",
    "            ds = superset[k]\n",
    "            target_att = ds[name]['train'][0].columns.tolist()[-1]\n",
    "            for fold in range(5):\n",
    "                print('.', end = '')\n",
    "                #Gather training data:\n",
    "                ds_train = ds[name]['train'][fold]\n",
    "                X_train = ds_train.drop(labels=target_att, axis = 1)\n",
    "                y_train = ds_train[target_att]\n",
    "            \n",
    "                # Gather test data:\n",
    "                ds_test = ds[name]['test'][fold]\n",
    "                X_test = ds_test.drop(labels=target_att, axis = 1)\n",
    "                y_test = ds_test[target_att]\n",
    "                \n",
    "                # Train model with the training data, \n",
    "                # If we need y_score for calculating ROC-AUC we do:\n",
    "                #y_score = model.fit(X_train, y_train).decision_function(X_test)\n",
    "                \n",
    "                # If we won't calculate ROC-AUC, we can just fit the model.\n",
    "                # If it is an ensemble model that needs prefit base models, we fit them first:\n",
    "                pool.fit(X_train, y_train)\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # Test model:\n",
    "                y_pred = model.predict(X_test)\n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                recall = recall_score(y_test, y_pred, pos_label='positive')\n",
    "                precision = precision_score(y_test, y_pred, pos_label='positive', zero_division=0)\n",
    "                f1 = f1_score(y_test, y_pred, pos_label='positive', zero_division=0)\n",
    "                gmean = geometric_mean_score(y_test, y_pred, pos_label='positive')\n",
    "                #roc_auc = roc_auc_score(y_test, y_score)\n",
    "\n",
    "                # Store metrics for this fold\n",
    "                acc_folds.append(acc)\n",
    "                recall_folds.append(recall)\n",
    "                precision_folds.append(precision)\n",
    "                f1_folds.append(f1)\n",
    "                #roc_auc_folds.append(roc_auc)\n",
    "                gmean_folds.append(gmean)\n",
    "            \n",
    "            new_row = {'Dataset' : name, 'Scaling technique' : k, 'Model' : model_name,\n",
    "                       'acc_fold1' : acc_folds[0], 'acc_fold2' : acc_folds[1], 'acc_fold3' : acc_folds[2], \n",
    "                       'acc_fold4' : acc_folds[3], 'acc_fold5' : acc_folds[4], \n",
    "                       'acc_mean': np.mean(acc_folds), 'acc_stddev': np.std(acc_folds),\n",
    "                       'recall_fold1' : recall_folds[0], 'recall_fold2' : recall_folds[1], 'recall_fold3' : recall_folds[2],\n",
    "                       'recall_fold4' : recall_folds[3], 'recall_fold5' : recall_folds[4], \n",
    "                       'recall_mean': np.mean(recall_folds), 'recall_stddev':np.std(recall_folds),\n",
    "                       'precision_fold1' : precision_folds[0], 'precision_fold2' : precision_folds[1] , 'precision_fold3' : precision_folds[2],\n",
    "                       'precision_fold4' : precision_folds[3], 'precision_fold5' : precision_folds[4],\n",
    "                       'precision_mean': np.mean(precision_folds), 'precision_stddev': np.std(precision_folds),\n",
    "                       'f1_fold1' : f1_folds[0], 'f1_fold2' : f1_folds[1], 'f1_fold3' : f1_folds[2], \n",
    "                       'f1_fold4' : f1_folds[3], 'f1_fold5' : f1_folds[4], \n",
    "                       'f1_mean': np.mean(f1_folds), 'f1_stddev': np.std(f1_folds),\n",
    "                       'gmean_fold1' : gmean_folds[0], 'gmean_fold2' : gmean_folds[1], 'gmean_fold3' : gmean_folds[2], \n",
    "                       'gmean_fold4' : gmean_folds[3], 'gmean_fold5' : gmean_folds[4], \n",
    "                       'gmean_mean': np.mean(gmean_folds), 'gmean_stddev' : np.std(gmean_folds)\n",
    "                      }\n",
    "\n",
    "            results_df = results_df.append(new_row, ignore_index=True)\n",
    "\n",
    "    print('\\nFinishing '+ model_name +', time: ', datetime.now(),'\\n')   \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running monolithic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to store results:\n",
    "results_df = pd.DataFrame({'Dataset' : [], 'Scaling technique' : [], 'Model' : [],\n",
    "                           'acc_fold1' : [], 'acc_fold2' : [], 'acc_fold3' : [], 'acc_fold4' : [], 'acc_fold5' : [], \n",
    "                           'acc_mean':[], 'acc_stddev':[],\n",
    "                           'recall_fold1' : [], 'recall_fold2' : [], 'recall_fold3' : [], 'recall_fold4' : [], 'recall_fold5' : [], \n",
    "                           'recall_mean':[], 'recall_stddev':[],\n",
    "                           'precision_fold1' : [], 'precision_fold2' : [], 'precision_fold3' : [], 'precision_fold4' : [], \n",
    "                           'precision_fold5' : [], 'precision_mean':[], 'precision_stddev': [],\n",
    "                           'f1_fold1' : [], 'f1_fold2' : [], 'f1_fold3' : [], 'f1_fold4' : [], 'f1_fold5' : [], \n",
    "                           'f1_mean': [], 'f1_stddev': [],\n",
    "                           'gmean_fold1' : [], 'gmean_fold2' : [], 'gmean_fold3' : [], 'gmean_fold4' : [], 'gmean_fold5' : [], \n",
    "                           'gmean_mean':[], 'gmean_stddev' : []\n",
    "                           })\n",
    "\n",
    "## Instantiating models:\n",
    "# Monolithic models\n",
    "monolithic_models = {'SVM_lin': SVC(kernel='linear', probability=True),\n",
    "                     'SVM_RBF': SVC(kernel='rbf', probability=True),\n",
    "                     'KNN': KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "                     'GNB': GaussianNB(),\n",
    "                     'GLVQ': GlvqModel(random_state=0), #Generalized Learning Vector Quantization\n",
    "                     'LDA': LinearDiscriminantAnalysis(),\n",
    "                     'QDA': QuadraticDiscriminantAnalysis(),\n",
    "                     'GP': GaussianProcessClassifier(1.0 * RBF(1.0), random_state=0, n_jobs=-1),\n",
    "                     'DT': DecisionTreeClassifier(random_state=0),\n",
    "                     'Percep': Perceptron(random_state=0, n_jobs=-1),\n",
    "                     'MLP': MLPClassifier(activation='relu', solver='adam', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=0)\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running models:\n",
    "for name,model in monolithic_models.items():\n",
    "        results_df = run_model(model, name, results_df)\n",
    "results_df.to_csv('csv_tabs/results_monolithic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to store results:\n",
    "results_df = pd.DataFrame({'Dataset' : [], 'Scaling technique' : [], 'Model' : [],\n",
    "                           'acc_fold1' : [], 'acc_fold2' : [], 'acc_fold3' : [], 'acc_fold4' : [], 'acc_fold5' : [], \n",
    "                           'acc_mean':[], 'acc_stddev':[],\n",
    "                           'recall_fold1' : [], 'recall_fold2' : [], 'recall_fold3' : [], 'recall_fold4' : [], 'recall_fold5' : [], \n",
    "                           'recall_mean':[], 'recall_stddev':[],\n",
    "                           'precision_fold1' : [], 'precision_fold2' : [], 'precision_fold3' : [], 'precision_fold4' : [], \n",
    "                           'precision_fold5' : [], 'precision_mean':[], 'precision_stddev': [],\n",
    "                           'f1_fold1' : [], 'f1_fold2' : [], 'f1_fold3' : [], 'f1_fold4' : [], 'f1_fold5' : [], \n",
    "                           'f1_mean': [], 'f1_stddev': [],\n",
    "                           'gmean_fold1' : [], 'gmean_fold2' : [], 'gmean_fold3' : [], 'gmean_fold4' : [], 'gmean_fold5' : [], \n",
    "                           'gmean_mean':[], 'gmean_stddev' : []\n",
    "                           })\n",
    "\n",
    "\n",
    "#  Ensemble models\n",
    "\n",
    "base_model = Perceptron(random_state=0)\n",
    "pool_classifiers = BaggingClassifier(base_estimator=base_model, n_estimators=100, random_state=0, bootstrap=True,\n",
    "                                bootstrap_features=False, max_features=1.0, n_jobs=-1)\n",
    "\n",
    "base_model_calib = CalibratedClassifierCV(base_estimator = Perceptron(random_state=0), cv=5) \n",
    "pool_classifiers_calib = BaggingClassifier(base_estimator=base_model_calib, n_estimators=100, random_state=0, bootstrap=True,\n",
    "                                bootstrap_features=False, max_features=1.0, n_jobs=-1) \n",
    "\n",
    "ensemble_models = {'RF': RandomForestClassifier(random_state = 0, n_jobs=-1),\n",
    "                   'XGBoost': XGBClassifier(n_jobs=-1, random_state=0),\n",
    "                   'AdaBoost': AdaBoostClassifier(n_estimators=100),\n",
    "                   'Bagging': pool_classifiers,\n",
    "                   'OLA': OLA(pool_classifiers, random_state=0),\n",
    "                   'LCA': LCA(pool_classifiers, random_state=0),\n",
    "                   'MCB': MCB(pool_classifiers, random_state=0),\n",
    "                   'KNORAE': KNORAE(pool_classifiers, random_state=0),\n",
    "                   'KNORAU': KNORAU(pool_classifiers, random_state=0),\n",
    "                   #'METADES': METADES(pool_classifiers_calib, random_state=0)\n",
    "                  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running models:\n",
    "for name,model in ensemble_models.items():\n",
    "    if name in ['OLA','LCA','MCB', 'KNORAE', 'KNORAU']: # these metamodels need pool_classifiers to be fit before applying fit to the metamodel.\n",
    "        results_df = run_model2(model, name, pool_classifiers, results_df)\n",
    "    elif name in ['METADES']: #This also needs a prefit pool_classifiers but needs base_estimators to return probabilities too.\n",
    "        results_df = run_model2(model, name, pool_classifiers_calib, results_df)\n",
    "    else: \n",
    "        results_df = run_model(model, name, results_df)\n",
    "results_df.to_csv('csv_tabs/results_ensemble.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
